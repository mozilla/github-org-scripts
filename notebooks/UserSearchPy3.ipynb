{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "incorrectly_encoded_metadata": "jp-MarkdownHeadingCollapsed=true",
    "lines_to_next_cell": 0,
    "tags": []
   },
   "source": [
    "# User Search\n",
    "For use to:\n",
    "1. Try to find an account based on random knowledge\n",
    "2. List all orgs they belong to (from a subset)\n",
    "  - You will need org owner permissions to perform these searches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "lines_to_next_cell": 0
   },
   "source": [
    "# Boiler plate\n",
    "Skip/hide this. Common usage is below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "lines_to_next_cell": 0
   },
   "source": [
    "If you see this text, you may want to enable the nbextension \"Collapsable Headings\", so you can hide this in common usage."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true,
    "lines_to_next_cell": 0
   },
   "source": [
    "## Tune as needed\n",
    "\n",
    "There are several lru_cache using functions. Many of them are called len(orgs_to_check) times. If they are under sized, run times will get quite long. (Only the first query should be delayed - after that, all data should be in the cache.)\n",
    "\n",
    "See the \"cache reporting\" cell below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true,
    "lines_to_next_cell": 0
   },
   "source": [
    "#### Orgs to check"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "This should be replaced with a call for all orgs the creds has owner access for."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "# use the output of ./get_org_info.py --names-only for below\n",
    "if False: # use True for test mode\n",
    "    orgs_to_check = set(\n",
    "        \"\"\"\n",
    "        mozilla-services\n",
    "        nubisproject\n",
    "    \"\"\".split()\n",
    "    )\n",
    "else: # production\n",
    "    orgs_to_check = set(\n",
    "        \"\"\"\n",
    "    Mozilla-Commons\n",
    "    Mozilla-Games\n",
    "    Mozilla-TWQA\n",
    "    MozillaDPX\n",
    "    MozillaDataScience\n",
    "    MozillaFoundation\n",
    "    MozillaReality\n",
    "    MozillaSecurity\n",
    "    MozillaWiki\n",
    "    Pocket\n",
    "    Thunderbird-client\n",
    "    common-voice\n",
    "    devtools-html\n",
    "    firefox-devtools\n",
    "    fxos\n",
    "    fxos-eng\n",
    "    iodide-project\n",
    "    mdn\n",
    "    moz-pkg-testing\n",
    "    mozilla\n",
    "    mozilla-applied-ml\n",
    "    mozilla-archive\n",
    "    mozilla-b2g\n",
    "    mozilla-bteam\n",
    "    mozilla-conduit\n",
    "    mozilla-extensions\n",
    "    mozilla-frontend-infra\n",
    "    mozilla-iam\n",
    "    mozilla-it\n",
    "    mozilla-jetpack\n",
    "    mozilla-l10n\n",
    "    mozilla-lockbox\n",
    "    mozilla-lockwise\n",
    "    mozilla-metrics\n",
    "    mozilla-mobile\n",
    "    mozilla-partners\n",
    "    mozilla-platform-ops\n",
    "    mozilla-private\n",
    "    mozilla-rally\n",
    "    mozilla-releng\n",
    "    mozilla-services\n",
    "    mozilla-spidermonkey\n",
    "    mozilla-standards\n",
    "    mozilla-svcops\n",
    "    mozilla-tw\n",
    "    mozmeao\n",
    "    nss-dev\n",
    "    nubisproject\n",
    "    projectfluent\n",
    "    taskcluster\n",
    "    \"\"\".split()\n",
    "    )\n",
    "\n",
    "print(f\"{len(orgs_to_check):3d} orgs to check.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true,
    "lines_to_next_cell": 0
   },
   "source": [
    "## Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true,
    "lines_to_next_cell": 0
   },
   "source": [
    "### main code (CIS/IAM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Not every operator will have a valid token for the CIS system, so fail gently if not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "def check_CIS(email):\n",
    "    if _has_cis_access():\n",
    "        login = _get_cis_info(email)\n",
    "        display(f\"CIS info for {email} reports '{login}'\")\n",
    "        return login\n",
    "    else:\n",
    "        display(\"Skipping CIS check, no token available.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "print(sys.executable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "def _has_cis_access():\n",
    "    import os\n",
    "\n",
    "    return os.environ.get(\"CIS_CLIENT_ID\", \"\") and os.environ.get(\n",
    "        \"CIS_CLIENT_SECRET\", \"\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "_cis_bearer_token = None\n",
    "import requests\n",
    "\n",
    "\n",
    "def _get_cis_bearer_token():\n",
    "    global _cis_bearer_token\n",
    "    if _cis_bearer_token:\n",
    "        return _cis_bearer_token\n",
    "    else:\n",
    "        import requests\n",
    "\n",
    "        url = \"https://auth.mozilla.auth0.com/oauth/token\"\n",
    "        headers = {\"Content-Type\": \"application/json\"}\n",
    "        payload = {\n",
    "            \"client_id\": os.environ[\"CIS_CLIENT_ID\"],\n",
    "            \"client_secret\": os.environ[\"CIS_CLIENT_SECRET\"],\n",
    "            \"audience\": \"api.sso.mozilla.com\",\n",
    "            \"grant_type\": \"client_credentials\",\n",
    "        }\n",
    "        resp = requests.post(url, json=payload, headers=headers)\n",
    "        data = resp.json()\n",
    "        _cis_bearer_token = data[\"access_token\"]\n",
    "        return _cis_bearer_token\n",
    "\n",
    "\n",
    "def _get_cis_info(email):\n",
    "    import urllib.request, urllib.parse, urllib.error\n",
    "\n",
    "    bearer_token = _get_cis_bearer_token()\n",
    "    # first get the v4 id\n",
    "    url = (\n",
    "        \"https://person.api.sso.mozilla.com/v2/user/primary_email/{}?active=any\".format(\n",
    "            urllib.parse.quote(email)\n",
    "        )\n",
    "    )\n",
    "    headers = {\"Authorization\": f\"Bearer {bearer_token}\"}\n",
    "    resp = requests.get(url, headers=headers)\n",
    "    data = resp.json()\n",
    "    login = v4id = None\n",
    "    try:\n",
    "        v4id = data[\"identities\"][\"github_id_v4\"][\"value\"]\n",
    "    except KeyError:\n",
    "        pass\n",
    "    if v4id:\n",
    "        # if there was a v4 id, map it to a login, via graphQL\n",
    "        query = \"\"\"\n",
    "            query id_lookup($id_to_check: ID!) {\n",
    "              node(id: $id_to_check) {\n",
    "                ... on User {\n",
    "                  login\n",
    "                  id\n",
    "                  databaseId\n",
    "                }\n",
    "              }\n",
    "            }\n",
    "            \"\"\"\n",
    "        variables = '{ \"id_to_check\": \"' + str(v4id) + '\" }'\n",
    "        url = \"https://api.github.com/graphql\"\n",
    "        headers = {\"Authorization\": f\"Token {api_key}\"}\n",
    "        payload = {\n",
    "            \"query\": query,\n",
    "            \"variables\": variables,\n",
    "        }\n",
    "        resp = requests.post(url, headers=headers, json=payload)\n",
    "        try:\n",
    "            data = resp.json()\n",
    "            login = data[\"data\"][\"node\"][\"login\"]\n",
    "        except KeyError:\n",
    "            login = None\n",
    "    return login"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.executable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true,
    "lines_to_next_cell": 0
   },
   "source": [
    "### main code (GitHub)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "init_cell": true,
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# print some debug information\n",
    "import github3\n",
    "\n",
    "print(github3.__version__)\n",
    "print(github3.__file__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.executable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "print(sys.executable)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "init_cell": true,
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# set values here - you can also override below\n",
    "\n",
    "# get api key from environment, fall back to file\n",
    "import os\n",
    "\n",
    "api_key = os.environ.get(\"GITHUB_PAT\", \"\")\n",
    "if not api_key:\n",
    "    api_key = open(\".credentials\").readlines()[1].strip()\n",
    "if not api_key:\n",
    "    raise OSError(\"no GitHub PAT found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "init_cell": true,
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import ipywidgets, IPython\n",
    "print(ipywidgets.__file__)\n",
    "print(IPython.__file__)\n",
    "print(IPython.display.__file__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "init_cell": true,
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def print_limits(e=None, verbose=False):\n",
    "    if e:\n",
    "        #         display(\"API limit reached, try again in 5 minutes.\\n\")\n",
    "        display(str(e))\n",
    "\n",
    "    reset_max = reset_min = 0\n",
    "    limits = gh.rate_limit()\n",
    "    resources = limits[\"resources\"]\n",
    "    #     print(\"{:3d} keys: \".format(len(resources.keys())), resources.keys())\n",
    "    #     print(resources)\n",
    "    for reset in list(resources.keys()):\n",
    "        reset_at = resources[reset][\"reset\"]\n",
    "        reset_max = max(reset_at, reset_max)\n",
    "        if not resources[reset][\"remaining\"]:\n",
    "            reset_min = min(reset_at, reset_min if reset_min else reset_at)\n",
    "            if verbose:\n",
    "                print(\n",
    "                    \"EXPIRED for {} {}\".format(reset, resources[reset][\"remaining\"])\n",
    "                )\n",
    "        else:\n",
    "            if verbose:\n",
    "                print(\n",
    "                    \"remaining for {} {}\".format(reset, resources[reset][\"remaining\"])\n",
    "                )\n",
    "\n",
    "    if not reset_min:\n",
    "        print(\"No limits reached currently.\")\n",
    "    else:\n",
    "        print(\n",
    "                \"Minimum reset at {} UTC ({})\".format(\n",
    "                    time.asctime(time.gmtime(reset_min)),\n",
    "                    time.asctime(time.localtime(reset_min)),\n",
    "                )\n",
    "        )\n",
    "    print(\n",
    "            \"All reset at {} UTC ({})\".format(\n",
    "                time.asctime(time.gmtime(reset_max)),\n",
    "                time.asctime(time.localtime(reset_max)),\n",
    "            )\n",
    "    )\n",
    "\n",
    "\n",
    "try:\n",
    "    gh = github3.login(token=api_key)\n",
    "    print(f\"You are authenticated as {gh.me().login}\")\n",
    "except (github3.exceptions.ForbiddenError, github3.exceptions.ConnectionError) as e:\n",
    "    print(str(e))\n",
    "    print_limits()\n",
    "from functools import lru_cache\n",
    "\n",
    "print_limits()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "From here on, use ``gh`` to access all data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "@lru_cache(maxsize=128)\n",
    "def _search_for_user(user):\n",
    "    l = list(gh.search_users(query=\"type:user \" + user))\n",
    "    display(f\"found {len(l)} potentials for {user}\")\n",
    "    return l\n",
    "\n",
    "\n",
    "@lru_cache(maxsize=512)\n",
    "def _search_for_org(user):\n",
    "    l = list(gh.search_users(query=\"type:org \" + user))\n",
    "    display(f\"found {len(l)} potentials for {user}\")\n",
    "    return l\n",
    "\n",
    "\n",
    "def get_user_counts(user):\n",
    "    # display(u\"SEARCH '{}'\".format(user))\n",
    "    l = _search_for_user(user)\n",
    "    yield from l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "displayed_users = set()  # cache to avoid duplicate output\n",
    "\n",
    "\n",
    "def show_users(user_list, search_term):\n",
    "    global displayed_users\n",
    "    unique_users = set(user_list)\n",
    "    count = len(unique_users)\n",
    "    if count > 10:\n",
    "        # Even if there are too many, we still want to check the 'root' term, if it matched\n",
    "        try:\n",
    "            seed_user = gh.user(search_term.encode(\"ascii\", \"replace\"))\n",
    "            display(\n",
    "                \"... too many to be useful, still trying '{}' ...\".format(\n",
    "                    seed_user.login\n",
    "                )\n",
    "            )\n",
    "            displayed_users.add(seed_user)\n",
    "        #             print(\"search_term {}; seed_user {}; seed_user.login {}\".format(search_term, seed_user, seed_user.login))\n",
    "        except github3.exceptions.NotFoundError:\n",
    "            display(f\"... too many to be useful, '{search_term}' is not a user\")\n",
    "    else:\n",
    "        for u in [x for x in unique_users if not x in displayed_users]:\n",
    "            displayed_users.add(u)\n",
    "            user = u.user.refresh()\n",
    "    if 0 < count <= 10:\n",
    "        return [u.login for u in unique_users]\n",
    "    else:\n",
    "        return []\n",
    "\n",
    "\n",
    "from itertools import permutations\n",
    "\n",
    "\n",
    "def _permute_seeds(seeds):\n",
    "    if len(seeds) == 1:\n",
    "        yield seeds[0]\n",
    "    else:\n",
    "        for x, y in permutations(seeds, 2):\n",
    "            permutation = \" \".join([x, y])\n",
    "            display(f\"   trying phrase permutation {permutation}\")\n",
    "            yield permutation\n",
    "            permutation = \"\".join([x, y])\n",
    "            display(f\"   trying permutation {permutation}\")\n",
    "            yield permutation\n",
    "\n",
    "\n",
    "def gather_possibles(seeds):\n",
    "    found = set()\n",
    "    # sometimes get a phrase coming in - e.g. \"First Last\"\n",
    "    for seed in _permute_seeds(seeds.split()):\n",
    "        maybes = show_users(get_user_counts(seed), seed)\n",
    "        found.update(maybes)\n",
    "        # if it was an email addr, try again with the mailbox name\n",
    "        if \"@\" in seed:\n",
    "            seed2 = seed.split(\"@\")[0]\n",
    "            display(f\"Searching for mailbox name '{seed2}' (gather_possibles)\")\n",
    "            maybes = show_users(get_user_counts(seed2), seed2)\n",
    "            found.update(maybes)\n",
    "    return found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "class OutsideCollaboratorIterator(github3.structs.GitHubIterator):\n",
    "    def __init__(self, org):\n",
    "        super().__init__(\n",
    "            count=-1,  # get all\n",
    "            url=org.url + \"/outside_collaborators\",\n",
    "            cls=github3.users.ShortUser,\n",
    "            session=org.session,\n",
    "        )\n",
    "\n",
    "\n",
    "@lru_cache(maxsize=512)\n",
    "def get_collaborators(org):\n",
    "    collabs = [x.login.lower() for x in OutsideCollaboratorIterator(org)]\n",
    "    return collabs\n",
    "\n",
    "\n",
    "def is_collaborator(org, login):\n",
    "    return bool(login.lower() in get_collaborators(org))\n",
    "\n",
    "\n",
    "# provide same interface for members -- but the iterator is free :D\n",
    "@lru_cache(maxsize=512)\n",
    "def get_members(org):\n",
    "    collabs = [x.login.lower() for x in org.members()]\n",
    "    return collabs\n",
    "\n",
    "\n",
    "def is_member(org, login):\n",
    "    return bool(login.lower() in get_members(org))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "@lru_cache(maxsize=64)\n",
    "def get_org_owners(org):\n",
    "    owners = org.members(role=\"admin\")\n",
    "    logins = [x.login for x in owners]\n",
    "    return logins\n",
    "\n",
    "\n",
    "@lru_cache(maxsize=128)\n",
    "def get_inspectable_org_object(org_name):\n",
    "    try:\n",
    "        o = gh.organization(org_name)\n",
    "        # make sure we have enough chops to inspect it\n",
    "        get_org_owners(o)\n",
    "        is_member(o, \"qzu\" * 3)\n",
    "        is_collaborator(o, \"qzu\" * 3)\n",
    "    except github3.exceptions.NotFoundError:\n",
    "        o = None\n",
    "        display(f\"No such organization: '{org_name}'\")\n",
    "    except github3.exceptions.ForbiddenError as e:\n",
    "        o = None\n",
    "        display(f\"\\n\\nWARNING: Not enough permissions for org '{org_name}'\\n\\n\")\n",
    "    except Exception as e:\n",
    "        o = None\n",
    "        display(\"didn't expect to get here\")\n",
    "    return o\n",
    "\n",
    "\n",
    "def check_login_perms(logins, headers=None, ldap=None):\n",
    "    any_perms = []\n",
    "    any_perms.append(\"=\" * 30)\n",
    "    if headers:\n",
    "        any_perms.extend(headers)\n",
    "    if not len(logins):\n",
    "        any_perms.append(\"\\nFound no valid usernames\")\n",
    "    else:\n",
    "        any_perms.append(\n",
    "            \"\\nChecking {} usernames for membership in {} orgs\".format(\n",
    "                len(logins), len(orgs_to_check)\n",
    "            )\n",
    "        )\n",
    "        for login in logins:\n",
    "            start_msg_count = len(any_perms)\n",
    "            for org in orgs_to_check:\n",
    "                o = get_inspectable_org_object(org)\n",
    "                if o is None:\n",
    "                    continue\n",
    "                if is_member(o, login):\n",
    "                    url = \"https://github.com/orgs/{}/people?utf8=%E2%9C%93&query={}\".format(\n",
    "                        o.login, login\n",
    "                    )\n",
    "                    msg = f\"FOUND! {o.login} has {login} as a member: {url}\"\n",
    "                    owner_logins = get_org_owners(o)\n",
    "                    is_owner = login in owner_logins\n",
    "                    if is_owner:\n",
    "                        msg += f\"\\n  NOTE: {login} is an OWNER of {org}\"\n",
    "                    any_perms.append(msg)\n",
    "                if is_collaborator(o, login):\n",
    "                    url = \"https://github.com/orgs/{}/outside-collaborators?utf8=%E2%9C%93&query={}\".format(\n",
    "                        o.login, login\n",
    "                    )\n",
    "                    any_perms.append(\n",
    "                        \"FOUND! {} has {} as a collaborator: {}\".format(\n",
    "                            o.login, login, url\n",
    "                        )\n",
    "                    )\n",
    "            else:\n",
    "                end_msg_count = len(any_perms)\n",
    "                if end_msg_count > start_msg_count:\n",
    "                    # some found, put a header on it, the add blank line\n",
    "                    any_perms.insert(\n",
    "                        start_msg_count,\n",
    "                        \"\\nFound {:d} orgs for {}:\".format(\n",
    "                            end_msg_count - start_msg_count, login\n",
    "                        ),\n",
    "                    )\n",
    "                    any_perms.append(\"\")\n",
    "                else:\n",
    "                    any_perms.append(f\"No permissions found for {login}\")\n",
    "    return any_perms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "def extract_addresses(text):\n",
    "    \"\"\"Get email addresses from text.\"\"\"\n",
    "    # ASSUME that text is a list of email addresses (possibly empty)\n",
    "    if not text:\n",
    "        return []\n",
    "    #     print(\"before: %s\" % text)\n",
    "    text = text.replace(\"[\", \"\").replace(\"]\", \"\").replace(\"b'\", \"\").replace(\"'\", \"\")\n",
    "    #     print(\"after: %s\" % text)\n",
    "    #     print(\" split: %s\" % text.split())\n",
    "    return text.split()\n",
    "    # raise ValueError(\"couldn't parse '{}'\".format(text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### main driver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "# we get some insane counts sometimes, along with 404s as all of these\n",
    "# results are based on an index GitHub created some time ago, and include sha1\n",
    "# references. E.g. 404 link:\n",
    "#    https://github.com/mozilla-services/foxsec-results/blob/70a5b7841edcdb967beddbce75309efa0bc2b687/aws-pytest/cloudservices-aws-stage/one-offs/cloudservices-aws-stage-2018-01-31-secgroup-service-report.md/search?q=oremj&type=code\n",
    "# valid version\n",
    "#    https://github.com/mozilla-services/foxsec-results/blob/master/aws-pytest/cloudservices-aws-stage/one-offs/cloudservices-aws-stage-2018-01-31-secgroup-service-report.md\n",
    "# However, that URL won't support a search endpoint, so what we _really_ want is\n",
    "#    https://github.com/search?q=oremj+repo%3Amozilla-services%2Ffoxsec-results++path%3Aaws-pytest%2Fcloudservices-aws-stage%2Fone-offs%2F+filename%3Acloudservices-aws-stage-2018-01-31-secgroup-service-report.md&type=Code&ref=advsearch\n",
    "#    https://github.com/search?q=repo%3Amozilla-services/foxsec-results%20path%3Aaws-pytest/cloudservices-aws-stage/one-offs%20filename%3Acloudservices-aws-stage-2018-01-31-secgroup-service-report.md%20fred&type=code&ref=advsearch\n",
    "#\n",
    "# rebuild the file hit url into what we want\n",
    "\n",
    "from urllib.parse import urlparse, urlunparse, quote\n",
    "\n",
    "# only add extensions or repos that could NEVER contain an ACL definition\n",
    "extensions_to_skip = ( \".md\", \".rst\")\n",
    "repos_to_skip = (\n",
    "    \"mozilla-services/foxsec-results\",\n",
    ")\n",
    "\n",
    "def search_hit_to_url(url, login=None):\n",
    "    # split into components\n",
    "    parts = urlparse(url)\n",
    "    # break down the path\n",
    "    path_parts = parts.path.split('/')\n",
    "    repo = '/'.join(path_parts[1:3])\n",
    "    if repo in repos_to_skip:\n",
    "        return\n",
    "    filename = path_parts[-1]\n",
    "#     from pprint import pprint\n",
    "#     pprint(path_parts)\n",
    "#     print(f\"{repo}; {filename}\")\n",
    "    try:\n",
    "        if filename[filename.rindex('.'):] in extensions_to_skip:\n",
    "            return\n",
    "    except ValueError:\n",
    "        # file didn't have extension, so process it\n",
    "        pass\n",
    "    basepath = path_parts[3:-1]\n",
    "    #from IPython.core.debugger import Pdb; Pdb().set_trace()\n",
    "    if basepath[0] == \"blob\":\n",
    "        # get rid of 'blob' and sha1\n",
    "        basepath = basepath[2:]\n",
    "        \n",
    "    # build the new query string\n",
    "    basepath = '/'.join(basepath)\n",
    "    query_string = f\"\"\"q={quote(f\"repo:{repo} path:{basepath}/ filename:{filename} {login}\")}&type=Code&ref=advsearch\"\"\"\n",
    "        \n",
    "    # now rebuild the url\n",
    "    new_url = urlunparse((\n",
    "        parts.scheme,\n",
    "        parts.netloc,\n",
    "        \"search\",\n",
    "        None, # params\n",
    "        query_string,\n",
    "        None, # fragment\n",
    "    ))\n",
    "    return new_url, repo, basepath, filename\n",
    "\n",
    "# tests for every load of this cell\n",
    "test_url = [\n",
    "    \"\"\"https://github.com/mozilla-services/foxsec-results/blob/47f31f014cf21dc6e7e774ddc28e51a6f9eeba54/bucketlister/README.md\"\"\",\n",
    "    \"\"\"https://github.com/mozilla-services/product-delivery-tools/blob/47f31f014cf21dc6e7e774ddc28e51a6f9eeba54/bucketlister/README.md\"\"\",\n",
    "    \"\"\"https://github.com/mozilla-services/cloudops-docs/blob/0ff6ea92e394784aef55abd4b9f8b5d26306fe4b/TeamDiagrams/service_registry.csv\"\"\",\n",
    "#     \"\"\"https://github.com/mozilla-services/foxsec-results/blob/70a5b7841edcdb967beddbce75309efa0bc2b687/aws-pytest/cloudservices-aws-stage/one-offs/cloudservices-aws-stage-2018-01-31-secgroup-service-report.mxd/search?q=oremj&type=code\"\"\"\n",
    "#     \"\"\"https://github.com/mozilla-services/foxsec-results/blob/70a5b7841edcdb967beddbce75309efa0bc2b687/aws-pytest/cloudservices-aws-stage/one-offs/cloudservices-aws-stage-2018-01-31-secgroup-service-report.md/search?q=oremj&type=code\"\"\"\n",
    "]\n",
    "test_good = [\n",
    "    None, # should be skipped\n",
    "    None, # should be skipped\n",
    "    (\"\"\"https://github.com/search?q=repo%3Amozilla-services/cloudops-docs%20path%3ATeamDiagrams/%20filename%3Aservice_registry.csv%20oremj&type=Code&ref=advsearch\"\"\",\n",
    "    \"mozilla-services/cloudops-docs\", \"TeamDiagrams\", \"service_registry.csv\")\n",
    "#     \"\"\"https://github.com/search?q=repo%3Amozilla-services/foxsec-results%20path%3Aaws-pytest/cloudservices-aws-stage/one-offs/%20filename%3Acloudservices-aws-stage-2018-01-31-secgroup-service-report.mxd%20oremj&type=Code&ref=advsearch\"\"\",\n",
    "#     None, # should be skipped\n",
    "]\n",
    "test_login = \"oremj\"\n",
    "for test, success in zip(test_url, test_good):\n",
    "    actual = search_hit_to_url(test, test_login)\n",
    "    if actual != success:\n",
    "        print(f\"test case: {test}\")\n",
    "        print(f\" received: {actual}\")\n",
    "        print(f\" expected: {success}\")\n",
    "        raise SystemExit(\"unit test failed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "init_cell": true,
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def check_for_acls(logins, ldap=None):\n",
    "\n",
    "    \"\"\" Check for these items in code, could be an acl to be removed\n",
    "    \n",
    "    Note that we haven't pruned logins to just the orgs we found hits on -- we're using all GitHub logins. May want to modify in the future.\n",
    "    \"\"\"\n",
    "    possibles = set()\n",
    "    possibles.update(logins)\n",
    "    if ldap is not None:\n",
    "        possibles.add(ldap)\n",
    "    hits = [f\"\\nChecking for possible ACLs for: {', '.join(possibles)}\\n\"]\n",
    "    for org in orgs_to_check:\n",
    "        print(f\" {org}..\", end='')\n",
    "        for l in possibles:\n",
    "            full_list = []\n",
    "            try:\n",
    "                full_list = list(gh.search_code(query=f\"org:{org} {l}\"))\n",
    "            except Exception as e:\n",
    "                if e.code not in [403, 422]:\n",
    "                    print(f\"org={org} l={l} exception={str(e)}\")\n",
    "                elif e.code in [403]:\n",
    "                    print(\"\\n\\nOut of API calls, waiting a minute ..\", end='')\n",
    "                    print_limits(verbose=True)\n",
    "                    # we can hit this a lot, so just wait a minute\n",
    "                    time.sleep(60)\n",
    "                    print(\"... resumed.\")\n",
    "                else:\n",
    "                    print(f\"Got code {e.code} for org {org}, search {l}\")\n",
    "            # remove vulnerability repos (*-ghsa-*) and archived repos (archive status \n",
    "            # requires refresh of repository object\n",
    "            hit_list = [r for r in full_list if (not \"-ghsa-\" in r.repository.name)\n",
    "                                            and (not r.repository.refresh().archived)]\n",
    "            num_search_results = len(hit_list)\n",
    "\n",
    "            search_urls = []\n",
    "            for search_hit in hit_list:\n",
    "                new_url = search_hit_to_url(search_hit.html_url, l)\n",
    "#                 print(f\"before: {search_hit.html_url}\\n after: {new_url}\")\n",
    "                if new_url:\n",
    "                    search_urls.append(new_url)\n",
    "            num_raw_search_urls = len(search_urls)\n",
    "            search_urls = set(search_urls)\n",
    "            num_search_urls = len(search_urls)\n",
    "            print(f\"search results: {num_search_results}; after translation: {num_raw_search_urls}; after dedupe: {num_search_urls}\")\n",
    "            if num_search_urls > 0:\n",
    "                hits.append(f\"{num_search_urls} files with possible ACLs in {org}:\")\n",
    "                for url, repo, path, filename in sorted(search_urls):\n",
    "                    # output in gfm checklist syntax\n",
    "                    hits.append(f\"- [ ] [{repo}/{path}/{filename}]({url})\")\n",
    "            # import pdb ; pdb.set_trace()\n",
    "    return hits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "\n",
    "re_flags = re.MULTILINE | re.IGNORECASE\n",
    "\n",
    "\n",
    "def process_from_email(email_body):\n",
    "    # get rid of white space\n",
    "    email_body = os.linesep.join(\n",
    "        [s.strip() for s in email_body.splitlines() if s.strip()]\n",
    "    )\n",
    "    if not email_body:\n",
    "        return\n",
    "\n",
    "    user = set()\n",
    "\n",
    "    # Extract data from internal email format\n",
    "    match = re.search(r\"^Full Name: (?P<full_name>\\S.*)$\", email_body, re_flags)\n",
    "    if match:\n",
    "        # add base and some variations\n",
    "        full_name = match.group(\"full_name\")\n",
    "        user.add(full_name)\n",
    "        # remove spaces, forward & reversed\n",
    "        user.add(full_name.replace(\" \", \"\"))\n",
    "        user.add(\"\".join(full_name.split()[::-1]))\n",
    "        # use hypens, forward & reversed\n",
    "        user.add(full_name.replace(\" \", \"-\"))\n",
    "        user.add(\"-\".join(full_name.split()[::-1]))\n",
    "\n",
    "    match = re.search(r\"^Email: (?P<primary_email>.*)$\", email_body, re_flags)\n",
    "    primary_email = match.group(\"primary_email\") if match else None\n",
    "    user.add(primary_email)\n",
    "    default_login = primary_email.split(\"@\")[0] if primary_email else None\n",
    "    if default_login:\n",
    "        # add some common variations that may get discarded for \"too many\" matches\n",
    "        user.update(\n",
    "            [\n",
    "                f\"moz{default_login}\",\n",
    "                f\"moz-{default_login}\",\n",
    "                f\"mozilla{default_login}\",\n",
    "                f\"mozilla-{default_login}\",\n",
    "                f\"{default_login}moz\",\n",
    "                f\"{default_login}-moz\",\n",
    "            ]\n",
    "        )\n",
    "\n",
    "    # let user start manual work before we do all the GitHub calls\n",
    "    display(\"Check these URLs for Heroku activity:\")\n",
    "    display(\n",
    "        \"  Heroku Access: https://people.mozilla.org/a/heroku-members/edit?section=members\"\n",
    "    )\n",
    "    display(f\"     copy/paste for ^^ query:  :{primary_email}:  \")\n",
    "    display(\n",
    "        \"  People: https://people.mozilla.org/s?who=all&query={}\".format(\n",
    "            primary_email.replace(\"@\", \"%40\")\n",
    "        )\n",
    "    )\n",
    "    display(\n",
    "        \"  Heroku: https://dashboard.heroku.com/teams/mozillacorporation/access?filter={}\".format(\n",
    "            primary_email.replace(\"@\", \"%40\")\n",
    "        )\n",
    "    )\n",
    "    display(email_body)\n",
    "\n",
    "    match = re.search(r\"^Github Profile: (?P<github_profile>.*)$\", email_body, re_flags)\n",
    "    declared_github = match.group(\"github_profile\") if match else None\n",
    "    user.add(declared_github)\n",
    "    display(f\"Declared GitHub {declared_github}\")\n",
    "\n",
    "    # check CIS for verified login (not all users will have creds)\n",
    "    verified_github_login = check_CIS(primary_email)\n",
    "    if verified_github_login:\n",
    "        user.add(verified_github_login)\n",
    "        display(f\"Verified GitHub {verified_github_login}\")\n",
    "\n",
    "    match = re.search(r\"^Zimbra Alias: (?P<other_email>.*)$\", email_body, re_flags)\n",
    "    possible_aliases = extract_addresses(match.group(\"other_email\") if match else None)\n",
    "    user.update(possible_aliases)\n",
    "\n",
    "    # new field: Email Alias -- list syntax (brackets)\n",
    "    match = re.search(r\"^Email Alias: \\s*\\[(?P<alias_email>.*)\\]\", email_body, re_flags)\n",
    "    user.add(match.group(\"alias_email\") if match else None)\n",
    "\n",
    "    # we consider each token in the IM line as a possible GitHub login\n",
    "    match = re.search(r\"^IM:\\s*(.*)$\", email_body, re_flags)\n",
    "    if match:\n",
    "        im_line = match.groups()[0]\n",
    "        matches = re.finditer(r\"\\W*((\\w+)(?:\\s+\\w+)*)\", im_line)\n",
    "        user.update([x.group(1) for x in matches] if matches else None)\n",
    "\n",
    "    match = re.search(r\"^Bugzilla Email: (?P<bz_email>.*)$\", email_body, re_flags)\n",
    "    user.add(match.group(\"bz_email\") if match else None)\n",
    "\n",
    "    # grab the department name, for a heuristic on whether we expect to find perms\n",
    "    expect_github_login = False\n",
    "    match = re.search(r\"^\\s*Dept Name: (?P<dept_name>\\S.*)$\", email_body, re_flags)\n",
    "    if match:\n",
    "        department_name = match.groups()[0].lower()\n",
    "        dept_keys_infering_github = [\"firefox\", \"engineering\", \"qa\", \"operations\"]\n",
    "        for key in dept_keys_infering_github:\n",
    "            if key in department_name:\n",
    "                expect_github_login = True\n",
    "                break\n",
    "\n",
    "    # clean up some noise, case insensitively, \"binary\" markers\n",
    "    user = {x.lower() for x in user if x and (len(x) > 2)}\n",
    "    to_update = [x[2:-1] for x in user if (x.startswith(\"b'\") and x.endswith(\"'\"))]\n",
    "    user.update(to_update)\n",
    "    user = {x for x in user if not (x.startswith(\"b'\") and x.endswith(\"'\"))}\n",
    "\n",
    "    # the tokens to ignore are added based on discovery,\n",
    "    # they tend to cause the searches to get rate limited.\n",
    "    user = user - {\n",
    "        None,\n",
    "        \"irc\",\n",
    "        \"slack\",\n",
    "        \"skype\",\n",
    "        \"b\",\n",
    "        \"hotmail\",\n",
    "        \"mozilla\",\n",
    "        \"ro\",\n",
    "        \"com\",\n",
    "        \"softvision\",\n",
    "        \"mail\",\n",
    "        \"twitter\",\n",
    "        \"blog\",\n",
    "        \"https\",\n",
    "        \"jabber\",\n",
    "        \"net\",\n",
    "        \"github\",\n",
    "        \"gmail\",\n",
    "        \"facebook\",\n",
    "        \"guy\",\n",
    "        \"pdx\",\n",
    "        \"yahoo\",\n",
    "        \"aim\",\n",
    "        \"whatsapp\",\n",
    "        \"gtalk\",\n",
    "        \"google\",\n",
    "        \"gpg\",\n",
    "        \"telegram\",\n",
    "        \"keybase\",\n",
    "        \"zoom\",\n",
    "        \"name\",\n",
    "    }\n",
    "    global displayed_users\n",
    "    displayed_users = set()\n",
    "    try:\n",
    "        headers = [\n",
    "            \"Search seeds: '{}'\".format(\"', '\".join(user)),\n",
    "        ]\n",
    "        display(*headers)\n",
    "        guesses = set()\n",
    "        for term in user:\n",
    "            possibles = gather_possibles(term)\n",
    "            guesses.update({x.lower() for x in possibles})\n",
    "        # include declared_github if it exists\n",
    "        if declared_github:\n",
    "            guesses.add(declared_github.lower())\n",
    "        guesses.update({x.login.lower() for x in displayed_users})\n",
    "        display(f\"Checking logins {guesses}\")\n",
    "        msgs = []\n",
    "        msgs = check_login_perms(guesses, headers)\n",
    "        found_perms = \"FOUND!\" in \"\".join(msgs)\n",
    "        display(f\"msgs {len(msgs)}; headers {len(headers)}\")\n",
    "        display(\n",
    "            \"found_perms {}; declared_github {} {}\".format(\n",
    "                found_perms, declared_github, bool(declared_github)\n",
    "            )\n",
    "        )\n",
    "\n",
    "        if declared_github and not found_perms:\n",
    "            msgs.append(f\"Even for declared login '{declared_github}'.\")\n",
    "        if expect_github_login and not found_perms:\n",
    "            msgs.append(\n",
    "                \"WARNING: expected GitHub permissions for dept '{}'\".format(\n",
    "                    department_name\n",
    "                )\n",
    "            )\n",
    "        \n",
    "        # check for GitHub login or ldap in a file (might be permissions)\n",
    "        display(\"Looking for ACLs\")\n",
    "        new_msgs = check_for_acls(guesses, default_login)\n",
    "        msgs.extend(new_msgs)\n",
    "        msgs.append(\"Finished all reporting.\")\n",
    "        display(*msgs)\n",
    "    except github3.exceptions.ForbiddenError as e:\n",
    "        print_limits(e)\n",
    "        raise e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "from ipywidgets import interact_manual, Layout, widgets\n",
    "from IPython.display import display\n",
    "\n",
    "text = widgets.Textarea(\n",
    "    value=\"email: \\nim: \",\n",
    "    placeholder=\"Paste ticket description here!\",\n",
    "    description=\"Email body:\",\n",
    "    layout=Layout(width=\"95%\"),\n",
    "    disabled=False,\n",
    ")\n",
    "\n",
    "run_process = interact_manual.options(manual_name=\"Process\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "def display(*args):\n",
    "    # iPyWidgets don't like unicode - ensure everything we try to put there is ascii\n",
    "    text = \"\\n\".join(\n",
    "        [str(x) for x in args]\n",
    "    )  # deal with None values by casting to unicode\n",
    "    # python 3 no longer requires us to play the convert-to-ascii game\n",
    "    cleaned = text  #.encode(\"ascii\", \"replace\")\n",
    "    if cleaned.strip():\n",
    "        print(str(cleaned))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "def check_github_logins(logins):\n",
    "    logins_to_check = set(logins.split())\n",
    "    # import pdb; pdb.set_trace()\n",
    "    for login in logins_to_check:\n",
    "        print(\"\\nworking on %s:\" % login)\n",
    "        msgs = check_login_perms([login])\n",
    "        display(*msgs)\n",
    "    msgs = check_for_acls(logins_to_check)\n",
    "    display(*msgs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### Cache Tuning & Clearing\n",
    "\n",
    "Various functions use lru_cache -- this outputs the values to see if they are tuned appropriately.\n",
    "\n",
    "Note that these have no meaning until after 1 or more queries have been run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "print(\"_search_for_user\")\n",
    "print(_search_for_user.cache_info())\n",
    "print(\"_search_for_org\")\n",
    "print(_search_for_org.cache_info())\n",
    "\n",
    "print(\"get_collaborators\")\n",
    "print(get_collaborators.cache_info())\n",
    "print(\"get_members\")\n",
    "print(get_members.cache_info())\n",
    "\n",
    "print(\"get_org_owners\")\n",
    "print(get_org_owners.cache_info())\n",
    "print(\"get_inspectable_org_object\")\n",
    "print(get_inspectable_org_object.cache_info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "print(\"clearing caches...\")\n",
    "_search_for_user.cache_clear()\n",
    "_search_for_org.cache_clear()\n",
    "get_collaborators.cache_clear()\n",
    "get_members.cache_clear()\n",
    "get_org_owners.cache_clear()\n",
    "get_inspectable_org_object.cache_clear()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### EML file support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "init_cell": true,
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# read EML file support\n",
    "import email\n",
    "from ipywidgets import FileUpload\n",
    "from pprint import pprint as pp\n",
    "from IPython.display import display as display_widget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def extract_reply(body):\n",
    "    extracted = []\n",
    "    for l in body.split(\"\\r\\n\"):\n",
    "        if l.startswith(\"> --\"):\n",
    "            break\n",
    "        elif l.startswith(\"> \"):\n",
    "            extracted.append(l[2:])\n",
    "    return extracted\n",
    "\n",
    "\n",
    "def process_from_file(uploader):\n",
    "    # message = email.message_from_string()\n",
    "    for file in list(uploader.value.keys()):\n",
    "        print(\"checking %s\" % file)\n",
    "        pp(list(uploader.value[file].keys()))\n",
    "        content = uploader.value[file][\"content\"]\n",
    "        pp(type(content))\n",
    "        pp(type(uploader.value[file]))\n",
    "        #pp(uploader.value[file])\n",
    "        message = email.message_from_bytes(content)\n",
    "        #message = email.message_from_string(uploader.value[file][\"content\"])\n",
    "        for part in message.walk():\n",
    "            if part.get_content_maintype() == \"multipart\":\n",
    "                continue\n",
    "            else:\n",
    "                mime = part.get_content_type()\n",
    "                if \"plain\" in mime:\n",
    "                    body = part.get_payload()\n",
    "                    # this could be the original, or a reply\n",
    "                    if re.search(r\"\"\"^Full Name:\"\"\", body, re_flags):\n",
    "                        print(\"original email:\")\n",
    "                        process_from_email(body)\n",
    "                    elif re.search(r\"\"\"^> Full Name:\"\"\", body, re_flags):\n",
    "                        print(\"reply:\")\n",
    "                        process_from_email(\"\\n\".join(extract_reply(body)))\n",
    "                    else:\n",
    "                        print(\"no match!\\n%s\" % body)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "# Start of common usage (How To)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "Currently, there are three common use cases:\n",
    "- processing an offboarding email (via downloaded EML file),\n",
    "- processing an offboarding email (via message copy/paste), and\n",
    "- adhoc lookup of GitHub login\n",
    "\n",
    "For anything else, you're on your own!\n",
    "\n",
    "All usage requires the following setup:\n",
    "1. Supply your PAT token via the environment variable `GITHUB_PAT` when starting the notebook server. (If you can't do that, read the code for another way.)\n",
    "2. Supply your CIS credentials via the environment variables `CIS_CLIENT_ID` and `CIS_CLIENT_SECRET`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "## EML File parsing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Upload the file using the button below, then process that file by running the cell below the button. You can only process one file at a time, but the \"file uploaded\" count will continue to increase (ui glitch)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "init_cell": true,
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "_uploader = FileUpload(accept=\"*.eml\", multiple=False)\n",
    "display_widget(_uploader)\n",
    "# check_file(_uploader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 1,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def check_file(f):\n",
    "    try:\n",
    "        # display_widget(_uploader)\n",
    "        process_from_file(f)\n",
    "        print(\"completed\")\n",
    "    except Exception as e:\n",
    "        print(repr(e))\n",
    "        raise\n",
    "\n",
    "\n",
    "check_file(_uploader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "lines_to_next_cell": 0
   },
   "source": [
    "## Process offboarding email body text (copy/paste)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Usage steps - for each user:\n",
    "    1. Copy entire text of email\n",
    "    2. Paste into the text area below\n",
    "    3. Click the \"Process\" button\n",
    "    4. Use the generated links to check for Heroku authorization\n",
    "    5. After \"process finished\" printed, copy/paste final output into email"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "@run_process(t=text)\n",
    "def show_matches(t):\n",
    "    try:\n",
    "        process_from_email(t)\n",
    "    except Exception as e:\n",
    "        print(repr(e))\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "lines_to_next_cell": 0
   },
   "source": [
    "## Adhoc Lookup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Fill in list of the desired logins in the cell below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "check_github_logins(\n",
    "    \"\"\" \n",
    " \"\"\"\n",
    ")\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "lines_to_next_cell": 0
   },
   "source": [
    "# To Do"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "- check invites as well, using manage_invitations.py\n",
    "- code doesn't handle hyphenated github logins, e.g. 'marco-c' (gets split)\n",
    "- github lookup should strip https... so can use link from people.m.o\n",
    "- dpreston, aka fzzy, doesn't have any GitHub perms\n",
    "- fix permutations of names\n",
    "- preprocess to remove all (colon separated) :b':':[:]: (maybe not the :b: & :':)\n",
    "- add link to Heroku service accounts to check\n",
    "\n",
    "\n",
    "- ~~GitHub login no longer part of email, but user id is available via CIS~~\n",
    "- ~~add \"clear cache\" button to purge after long idle~~ _(in tuning section)_\n",
    "- ~~add common login with 'moz{,illa}' taked on, sometimes with a dash~~\n",
    "- ~~update link to view access group on people.m.o~~\n",
    "- ~~add \"trying\" info to copy/paste output~~\n",
    "- ~~double check that \"even for declared login\" code still active~~\n",
    "- ~~add formatted output summary for copy/paste~~\n",
    "- ~~when a guess is multiple words, each word should be tried separately as well~~\n",
    "- ~~code should always search for stated github, even if search is \"too many\" (e.g. \"past\")~~\n",
    "- ~~does not call out owner status (reports as member)~~\n",
    "- ~~add short ldap name as an \"always check\"~~\n",
    "- ~~always check stem when search gives too many (i.e. go for the exact match)~~\n",
    "- ~~treat Zimbra Aliases as a potential multi valued list (or empty)~~\n",
    "- ~~\"-\" is a valid character in GitHub logins. Try as separator first-last and last-first~~\n"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Initialization Cell",
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "jupytext": {
   "formats": "ipynb,py:percent"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
